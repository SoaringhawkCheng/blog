---
title: 「面试系统设计题」学习笔记（上）
catalog: true
date: 2022-04-15 17:18:57
subtitle:
header-img:
tags:
- architecture
categories:
- 工程
---

> 参考资料链接：[高并发系统设计40问](https://zq99299.github.io/note-architect/hc/) [系统设计题精选](https://soulmachine.gitbooks.io/system-design/content/cn/)
> 
> 书籍豆瓣链接： 
> 
> 开始学习时间：
> 
> 预计完成时间：
> 
> 实际完成时间：

# 一、基础篇

## 1.1 通用设计方法
高并发系统的演进应该是循序渐进，以解决系统中存在的问题为目的和驱动力的。通用方法：Scale-up、Scale-out、缓存和异步

## 1.2 为何需要架构分层
业务越来越复杂，大量的代码纠缠在一起，会出现逻辑不清晰、各模块相互依赖、代码扩展性差、改动一处就牵一发而动全身等问题

### 1.2.1 什么是分层架构
「MVC」（Model-View-Controller）架构，将系统分成Model（模型），View（视图）和 Controller（控制器）三个层次，将用户视图和业务处理隔离开，并且通过控制器连接起来，很好地实现了 表现和逻辑的解耦

另外一种常见的分层方式是将整体架构分为表现层、逻辑层和数据访问层，通常会建立三个目录：Web、Service 和 Dao：

1. 表现层，顾名思义嘛，就是展示数据结果和接受用户指令的，是最靠近用户的一层；
2. 逻辑层里面有复杂业务的具体实现；
3. 数据访问层则是主要处理和存储之间的交互。

OSI 网络模型，它把整个网络分了七层，TCP/IP 协议，它把网络简化成了四层。隔离关注点，让不同的层专注做不同的事情。

Linux 文件系统也是分层设计的，某些层次负责的是对下层不同实现的抽象，从而对上层屏蔽实现细节：

1. 最上层是 虚拟文件系统（VFS），用来屏蔽不同的文件系统之间的差异，提供统一的系统调用接口
2. 虚拟文件系统的下层是 Ext3、Ext4 等各种文件系统
3. 再向下是为了屏蔽不同硬件设备的实现细节，我们抽象出来的单独的一层——通用块设备层
4. 然后就是不同类型的磁盘了

### 1.2.2 分层的好处

1. 简化系统设计，让不同的人专注做某一层次的事情
2. 分层之后可以做到很高的复用
3. 分层架构可以让我们更容易做横向扩展。比如说，业务逻辑里面包含有比较复杂的计算，导致 CPU 成为性能的瓶颈，那这样就可以把逻辑层单独抽取出来独立部署

### 1.2.3 分层架构的不足

1. 最主要的一个缺陷就是增加了代码的复杂度
2. 多层的架构在性能上会有损耗

## 1.3  高并发系统设计目标

### 1.3.1 高并发系统设计三大目标

* 高性能：
* 高可用：
* 可扩展性：处理峰值流量，弹性扩容

### 1.3.2 性能优化准则

* 问题导向：不能盲目提早优化，
* 二八法则：20%精力解决80%性能问题，优化主要的性能瓶颈点
* 数据支撑：需要量化，耗时减少多少，吞吐量提高多少

### 1.3.3 如何做到高性能

#### 1.3.3.1 提高并行处理能力

增加系统的并行处理能力， `吞吐量 = 并发进程数 / 响应时间`，并行化加速比 `(Ws + Wp) / (Ws + Wp/s)`，Ws表示串行计算量，Wp表示并行计算量，`s表示并行进程数`，`1/(1-p+p/s)`

#### 1.3.3.2 减少任务响应时间

* CPU密集型：优化算法
* IO密集型：性能分析工具和监控

### 1.3.4 如何做到高可用

可用性指标分`故障平均间隔时间`和`故障平均恢复时间`

### 1.3.5 如何做到可扩展

#### 1.3.5.1 系统设计

* 故障转移：

分对等节点：节点都承担读写流量，节点中不保存状态

非对等节点：热备、冷备和温备。故障检测常用机制是「心跳」，选主算法Paxos，Raft

* 调用超时控制

* 降级：是为了保证核心服务的稳定而牺牲非核心服务的做法

* 限流：

#### 1.3.5.2 系统运维

灰度发布、故障演练

### 1.3.6 如何让系统易于扩展

#### 1.3.6.1 存储层的扩展性

按业务垂直拆分，水平分库分表，尽量不要使用分布式事务

#### 1.3.6.2 业务层的扩展性

三个维度考虑业务层的拆分方案，它们分别是：

* 业务纬度

* 重要性纬度

* 请求来源纬度

# 二、数据库

## 2.1 池化技术

减少频繁创建数据库链接的性能损耗，使用池化技术

### 2.1.1 用连接池预先建立数据库连接

### 2.1.2 用线程池预先创建线程

ThreadPoolExecutor 线程池

## 2.2 主从分离

单机运行mysql，大概可以支撑**千级别的TPS**和**万级别的QPS**

大部分系统的访问模型是读多写少，采用主从分离技术抗住更高的查询请求

主从读写分离有两个技术上的关键点：

* 数据的拷贝，主从复制
* 屏蔽主从分离带来的访问数据库方式的变化

### 2.2.1 主从复制

#### 2.2.1.1 流程原理

* 主节点

主节点创建log dump现成发送binlog给从库

* 从库

从库创建IO线程，请求主库更新的binlog，并写入relay log的日志文件中

从库创建创建一个SQL现成读取relay log，做回放

* 从库数量

对于每个从库，主库需要创建同样多的log dump现成来发送binlog，且受限于主库网络带宽。实际使用中，一般一个主库最多挂3-5个从库

#### 2.2.1.2 处理主从延迟

* 数据冗余

避免从数据库中重新查询数据。

足够简单优先考虑，会造成传输数据体较大

* 使用缓存

写数据库的时候，同步写缓存。

适合新增数据的场景，更新数据的场景会造成数据不一致

* 查询主库

一般不使用这个方案

### 2.2.2 如何访问数据库

使用数据库中间件

## 2.3 分库分表

数据库的写入请求量大造成的性能和可用性方面的问题，对数据进行分片，突破单机的容量和请求量的瓶颈

### 2.3.1 拆分方式

#### 2.3.1.1 垂直拆分

业务相关性

#### 2.3.1.2 水平拆分

哈希值拆分；区间拆分，如时间

### 2.3.1 引入问题

join和count查询无法实现，需要异构出一张宽表，或者使用分布式缓存

单库单表到分库分表改造，分库分表扩容，都是非常麻烦的。性能没有瓶颈尽量不分库分表，要分就一次到位，比如16库64表基本能满足几年内你的业务需求

NoSQL数据库，如Hbase和MongoDB都提供了auto sharding的特性，可以考虑替代关系型数据库

## 2.4 高并发场景下NoSQL和数据库的互补

NoSQL指的是不同于传统关系型数据库的数据库的统称，有下列分类：

kv存储数据库：Redis，LevelDb，相比传统数据库的优势是更高的读写性能

列式存储数据库：Hbase，Cassandra，按列来存储，适用于一些离线数据统计的场景

文档型数据库：MongoDB，CouchDB，特点是Schema Free

### 2.4.1 使用NoSQL提升写入性能

以 MySQL 的 InnoDB 存储引擎来说，更新 binlog、redolog、undolog 都是在做顺序 IO，而更新 datafile 和索引文件则是在做随机 IO

很多NoSQL使用了基于LSM的存储引擎，LSM树（Log-structure Merge Tree）牺牲了一定的读性能换取写入数据的高性能，比如LevelDb、Hbase、Cassandra

### 2.4.2 场景补充

传统数据库只能使用索引的最左前缀匹配，不支持全文搜索。全文搜索可以使用基于倒排索引作为核心技术原理的ElasticSearch

### 2.4.3 提升扩展性

NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性，比如mongoDB的可扩展性分为下面三个特性：

1. Replica，对应主从分离
2. Shard，对应分片
3. 负载均衡，减少了数据迁移和验证成本

### 2.4.4 使用NoSQL的注意点

NoSQL 可供选型的种类很多，每一个组件都有各自的特点。你在做选型的时候需要对它的实现原理有比较深入的了解，最好在运维方面对它有一定的熟悉，这样在出现问题时才能及时找到解决方案。 否则，盲目跟从地上了一个新的 NoSQL 数据库，最终可能导致会出了故障无法解决，反而成为整体系统的拖累。 

# 三、缓存

## 3.1 使用缓存解决数据库IO瓶颈

做一次内存寻址大概需要 100ns，而做一次磁盘的查找则需要 10ms，缓存作为一种常见的 空间换时间的性能优化手段

### 3.1.1 缓存案例

MMU通过TLB缓存虚拟地址与物理地址的映射

feed流的预加载

HTTP协议也有缓存机制，第一次请求静态资源，响应头有Etag字段，浏览器缓存这个字段。下次请求头里会有一个If-None-Match字段，并把Etag发给客户端。如果图片信息没有变化，则返回的304状态码

### 3.1.2 缓存与缓冲区

缓冲区则是一块临时存储数据的区域，这些数据后面会被传输到其他设备上，用以弥补高速设备和低速设备通信时的速度差

### 3.1.3 缓存分类

静态缓存：静态HTML页面

分布式缓存：Memcache、Redis

热点本地缓存：HashMap、Guava Cache、Ehcache。遇到极端的热点数据查询的时候，比如跑马灯，电商首页

### 3.1.4 缓存的不足

缓存更适用于读多写少的业务场景，并且数据最好带有一定的热点属性

缓存会给整体系统带来复杂度，会有数据不一致风险

缓存通常使用内存作为存储介质，成本较高不是无限制的

缓存会给运维带来一定的成本

## 3.2 如何选择缓存读写策略

### 3.2.1 Cache Aside（旁路缓存）策略

#### 3.2.1.1 读写策略

读策略：读更新缓存

写策略：更新并删除缓存

#### 3.2.1.2 存在问题

* 问题一：请求B的写更新，介于请求A的读更新之中，最终缓存中加载的还是旧数据

* 问题二：或者插入新数据后，因为数据库主从延迟读不到

* 问题三：对缓存命中率也有影响

#### 3.2.1.3 策略优化

更新缓存加分布式锁，对写入性能会有一定的影响

缓存过期时间缩短，即使出现不一致，缓存的数据也可以很快的过期

### 3.2.2 Read/Write Through 读穿/写穿策略

这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据

#### 3.2.2.1 写策略

查询缓存中数据是否存在，如果write miss：

1. 一种做法是write allocate，将数据库的数据导到缓存，再更新数据
2. 另一种做法是no-write allocate，不写入缓存，直接更新到数据库

一般使用no-write，提升写入性能

#### 3.2.2.2 读策略

缓存中没有，从数据库加载到缓存

#### 3.2.2.3 使用场景

用户只与缓存节点交互，redis和memcached不提供该功能，使用本地缓存可以考虑，比如Guava Cache中的Loading Cache

### 3.2.3 Write Back 写回策略

写入数据只写入缓存，并且将缓存标记为脏，计算机体系结构中的策略，异步将内存脏页刷回磁盘

## 3.3 缓存如何做到高可用

### 3.3.1 客户端方案

#### 3.3.1.1 写缓存分片

一致性哈希，为了提高平衡性，使用虚拟节点

一致性哈希，映射会发生改变，一定要设置缓存过期时间

#### 3.3.1.2

### 3.3.2 中间代理层方案

### 3.3.3 服务端方案

## 7. 计数系统设计
[](http://t.zoukankan.com/wt645631686-p-13878284.html)