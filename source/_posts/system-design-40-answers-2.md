---
title: 「高并发系统设计40问」学习笔记 （下）
catalog: true
date: 2022-04-15 17:18:58
subtitle:
header-img:
tags:
- architecture
categories:
- 工程
---

> 参考资料链接：[高并发系统设计40问](https://zq99299.github.io/note-architect/hc/) [系统设计题精选](https://soulmachine.gitbooks.io/system-design/content/cn/)
> 
> 书籍豆瓣链接： 
> 
> 开始学习时间：
> 
> 预计完成时间：
> 
> 实际完成时间：

# 四、消息队列

## 4.1 如何处理大量写请求

异步处理、解耦合和削峰填谷 是消息队列在秒杀系统设计中起到的主要作用


## 4.2处理消息丢失

### 4.2.1 消息生产阶段

使用重传，重试次数2-3次，但仍然有丢失的风险

### 4.2.2 消息队列阶段

为减少磁盘的随机I/O，会将消息写入操作系统的Page Cache中，然后异步刷入磁盘，这样会造成未持久化宕机造成的消息丢失

redis集群有leader提供消息写入和消费，多个follower负责数据的备份，leader故障就从follower的ISR选主

如果需要确保消息不丢失，生产者需要设置`acks=all`，每一条消息必须得到所有Leader和ISR确认才会被认为发送成功

### 4.2.3 消费过程阶段

一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题

## 4.3 如何保证消息只被消息一次

想要完全的避免消息重复的发生是很难做到的，只能保证在消息的生产和消费的过程是幂等的

### 4.3.1 消息不重复生产

给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID，消息队列的服务端会存储`<生产者 ID，最后一条消息ID>`的映射，丢失重复消息

### 4.3.2 消费端

通过版本号，发送消息查询版本号，消费后增加版本号，丢弃低版本号消息

## 4.4 如何降低消息队列系统消息的延迟

### 4.4.1 监控消息延迟

Kakfa 的一个专门的 topic 叫 `__consumer_offsets`，Kafka 安装包的 bin 目录下有个工具`kafka-consumer-groups.sh`，可以查看消息消费情况

### 4.4.2 优化消息延迟

#### 4.4.2.1 消费端

1. 提升consumer代码性能

2. 一个partition对应一个consumer，否则需要加锁。consumer创建一个线程池，一次拉取多条消息，分配给多个线程处理

3. 客户端拉取消息，采用递增步长，10ms拉不到，下次20ms，20ms拉不到下次100ms

#### 4.4.2.2 消息队列

1. 数据库写入qps只能到千级别，消息存储使用本地磁盘而不是数据库，page cache可以提升读取速度，因为消息读取是顺序的

2. 零拷贝，sendfile直接将数据从内核缓冲区拷贝到socket缓冲区，不经过用户缓冲区

# 五、分布式服务

## 5.1 每秒1w次请求的系统需要服务化拆分嘛

### 5.1.1 一体化架构的痛点

数据库连接数可能成为系统瓶颈

增加了研发的成本

增加系统运维的压力

### 5.1.2 如何使用微服务化解决这些痛点

数据库垂直分库，业务层拆分

增加中间层，将不同数据库的直接访问，转变为服务化抽象出公共服务

## 5.2 微服务化后，系统架构如何改造

### 5.2.1 微服务拆分原则

高内聚，低耦

先粗略拆分，随着业务的发展，再逐渐细化

拆分的过程中，尽量避免影响产品的日常功能迭代

服务接口的定义要具备可扩展性

### 5.2.2 微服务化带来的问题和解决思路

#### 5.2.2.1 服务间的调用变成进程间的网络调用

引入服务注册中心，管理的是服务完整的生命周期，包括对于服务存活状态的检测

#### 5.2.2.2 服务间依赖关系错综复杂

引入服务治理体系，采用熔断、降级、限流、超时控制的方法，使得问题被限制在单一服务中

#### 5.2.2.3 调用链路问题定位

引入分布式追踪工具，以及更细致的服务端监控报表

## 5.3 实现支持10w QPS的RPC框架

提升 RPC 框架的性能，需要从 网络传输和序列化 两方面来优化

### 5.3.1 网络传输优化

选择高性能的 I/O 模型，这里我推荐使用同步多路 I/O 复用模型

调试网络参数，比如将 tcp_nodelay 设置为 true，比如接受缓冲区和发送缓冲区的大小，客户端连接请求缓冲队列的大小（back log）

### 5.3.2 合适的序列化方式

性能要求不高，在传输数据占用带宽不大的场景下，可以使用 JSON

性能要求比较高，那么使用 Thrift 或者 Protobuf 都可以

一些存储的场景下，比如说你的缓存中存储的数据占用空间较大，那么你可以考虑使用 Protobuf 替换 JSON，作为存储数据的序列化方式

## 5.4 注册中心：分布式系统如何寻址

### 5.4.1 Nginx反向代理与注册中心

Nginx通过在配置文件中配置应用服务器的ip

注册中心：提供了服务地址的存储；存储内容发生变化时，可以将变更的内容推送给客户端

### 5.4.2 如何做服务管理

心跳机制

注册中心为每一个连接上来的 RPC 服务节点，记录最近续约的时间 ，RPC 服务节点在启动注册到注册中心后，就按照一定的时间间隔（比如 30 秒），向注册中心发送心跳包

## 5.5 分布式Trace

## 5.6 负载均衡

### 5.6.1 负载均衡种类

#### 5.6.1.1 代理类负载均衡服务

* LVS

* Nginx

LVS 在 OSI 网络模型中的第四层，传输层工作，所以 LVS 又可以称为四层负载；而 Nginx 运行在 OSI 网络模型中的第七层，应用层，所以又可以称它为七层负载

4层负载均衡基本就是基于 IP + 端口进行负载均衡；7层负载均衡可以基于不同的协议，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡

LVS 适合在入口处，承担大流量的请求分发，而 Nginx 要部署在业务服务器之前做更细维度的请求分发


#### 5.6.1.2 客户端负载均衡服务

### 5.6.2

## 5.7 API网关

## 5.8 多机房部署

## 5.9 ServiceMesh



# 六、维护

# 七、实战篇
